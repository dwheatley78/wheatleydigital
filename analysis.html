<!DOCTYPE html>
<html lang="en">
<head>
  

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EMPEDATA |  Generating Value Through Actionable Insights</title>
  <meta name=description content="Converting data into information to deliver value for your business"/>
 
  <link rel="stylesheet" href="css/bootstrap.min.css">
  <link rel="stylesheet" href ="css/style.css">
  <link rel="stylesheet" href ="css/tiles.css">
  <link rel="stylesheet" href ="css/modal.css">

  <link rel='shortcut icon' type='image/ico' href='images/icons/favicon.ico'/>
  <link rel="icon" type="image/png" sizes="32x32" href="images/icons/favicon-32x32.png">
  <link rel='icon' type='image/png' sizes="192x192" href='images/icons/android-chrome-192x192.png'/>
  <link rel='apple-touch-icon' type='image/png' sizes="512x512" href='images/icons/android-chrome-512x512.png'/>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  
  <link href='https://fonts.googleapis.com/css?family=Oxygen:400,300,700' rel='stylesheet' type='text/css'>


  <!-- jQuery (Bootstrap JS plugins depend on it) -->
  <script src="js/jquery-2.1.4.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/script.js"></script>


</head>

<body>
  <a name="top"></a>
  <nav id="header-nav" class="navbar navbar-default">
    <div class="container">
      <div class="navbar-header">
        <a href="index.html" class="pull-left visible-xs visible-sm visible-md visible-lg">
          <div id="logo-img" alt="logo image"></div>
        </a>
        <div class="navbar-brand">
          <a href="index.html"><p class="brand">EMPEDATA</p></a>
          <a href="index.html"><p>.com</p></a>
        </div>

        <button id="navbarToggle" type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#collapsable-nav" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      
      <div id="collapsable-nav" class="collapse navbar-collapse">
        <ul id="nav-list" class="nav navbar-nav navbar-right">
          <li>
            <a class="highlight" href="strategy.html">
              <span class="glyphicon glyphicon-dashboard"></span><br class="hidden-xs">Strategise</a>
          </li>
          <li>
            <a style="color:rgb(0,173,239)">
              <span class="glyphicon glyphicon-stats"></span><br class="hidden-xs">Analyse</a>
          </li>
          <li>
              <a class="highlight" href="production.html">
                <span class="glyphicon glyphicon-road"></span><br class="hidden-xs">Productionise</a>
          </li>
          <li>
            <a class="highlight" href="contact.html">
              <span class="glyphicon glyphicon-user"></span><br class="hidden-xs">Contact</a>
        </li>


        </ul><!-- #nav-list -->
      </div><!-- .collapse .navbar-collapse -->
    </div><!-- .container -->
  </nav><!-- #header-nav -->
        
  <div id="main_content" class="container">

    <div class="parallax jumbotron">
      <h1>Delivering Value through Actionable Insights</h1>
      <hr/>
      <a href = "mailto: david@empedata.com" style="color:white">Click to Email us</a>
    </div>
    
    <p>Analytics is the art of exploiting data to transform how your business operates. These analytical capabilities can be categorised as:
      <ul>
        <li><b>Descriptive</b> - Generally delivered through a dashboard, descriptive analytics enable you to report on what has happened.</li>
        <li><b>Diagnostic</b> - Leveraging statistical analysis diagnostics enable you to better understand the root cause of an event.</li>
        <li><b>Predictive</b> - Predictive analytics uses historic data to forecast what is likely to occur in the future.</li>
        <li><b>Prescriptive</b> - Taking this a step further, prescriptive analytics suggest the optimal action to be taken to achieve a desired outcome.</li>
        <li><b>Cognitive</b> - Taking the human out of the loop, cognitive analytics learn what actions to take to achieve a stated objective based on defined reward mechanism.</li>
      </ul>
    </p>
    <img src="images/analytics_cats.png" alt="types of analytics" class="center">
    <br/>  
    <p>
      Find out more about the analytical tools <span id="brand">EMPEDATA</span> use  to deliver actionable insights in the blocks below or <a href="./contact.html">get in touch</a>
       to arrange a private discussion to explore how we can help deliver your analytical needs.
    </p>



    <br>

    <h3 class="accordion">Business intelligence</h3>
    <div class="panel">
      <br/>
      <p style="padding:3px;clear:both;">Typically used for more straightforward querying and reporting of data, business intelligence tools combine data from a broad range of sources 
        to report business metrics via intuitive dashboards. These professional looking reports, that can be generated with little, or no, knowledge of coding provide a great way 
        to enable data driven decision making across your organisation and democratise your analytical capabilities. Popular business intelligence solutions include Microsoft's 
        <a href="https://powerbi.microsoft.com/en-gb/">PowerBI</a> and <a href="https://www.tableau.com/en-gb"   target="_blank">Tableau</a> produced by Salesforce.
      </p>
    </div>

    <h3 class="accordion">Mathematical modelling</h3>
    <div class="panel">
      <br/>
      <p style="padding:3px;clear:both;">Mathematical modelling covers a variety of techniques, all of which are fundamentally about building a representation of the provided data 
        with which to conduct analysis and infer relationships between variables. The 5 key mathematical modelling disciplines we consider are: 
      </p>
        <ul>
          <li><b>Mixed Integer Linear Programming (MILP)</b> -  By defining the variables, constraints and objective function of a problem the MILP algorithms identify the optimum solution 
            for a given problem. The <a href="https://www.gurobi.com/"   target="_blank">Gurobi</a> web site provides some fascinating case studies where MILP has been used to great effect and, at a 
            significant cost, is probably the most capable optimisation software available. Open-source Python alternatives such as <a href="http://www.pyomo.org/"   target="_blank">Pyomo</a> and 
            <a href="https://scipy.org/">Scipy</a> can provide similar capabilities, without the expense.</li>
          
          <li><b>Econometrics</b> - The goal of econometrics is to understand cause-effect and statistical significance of relationships, often within the scope of policy evaluation.  
            This information is invaluable when seeking to support recommended actions with empirical evidence.  Our preferred Python library when performing econometric analysis 
            is <a href="https://www.statsmodels.org/devel/index.html"   target="_blank">statsmodels</a>
          </li>
          <li><b>Network Analytics</b> - Networks, or graphs, provide a way to infer the level of connectivity and influence between objects.  Examples of these objects include, people, 
            companies in a supply chain and transport networks as exploited by the Google search engine, Facebook social network and various satnav route planning services.  
            <a href="https://networkx.org/">NetworkX</a> is an intuitive Python package with which to create and study networks but for larger scale analysis a dedicated Graph database, such as <a href="https://neo4j.com/">
              neo4j</a>, provide significant performance benefits. 
          </li>
          <li><b>Time series analysis </b> - Involves using ARIMA and ETS techniques to project forward the observed seasonality and underlying trends in a dataset to predict future events.  
            Again, our preferred Python library for performing this type of analysis is <a href="https://www.statsmodels.org/devel/index.html"   target="_blank">statsmodels</a>.</li>
          <li><b>Discreet Event Simulation</b> - Sometimes the best way to understand a phenomenon is to build a simulation. Running the simulation with a range of statistically controlled 
            input parameters and performing a Montecarlo analysis to determine the likelihood of a variety of outcomes.  Once understood optimisation algorithms can be applied to select 
            the best mitigating actions to be taken.  <a href="https://simpy.readthedocs.io/">Simpy</a> is a popular Python simulation library, although we generally prefer developing
            custom objects and generator functions to define a simulation environment and behaviours of actors within it. 
          </li>
        </ul>
    </div>

    <h3 class="accordion">Machine learning</h3>
    <div class="panel">
      <br/>
      <p style="padding:3px;clear:both;">Machine learning algorithms are used to predict an output value or classify an object based on the provided input variables. In contrast with mathematical modelling machine learning 
        focuses on making the best fit, not in understanding the underlying causality.  The main Python library for machine learning is <a href="https://scikit-learn.org/">Sci-kit learn</a>, which enables
        a wide variety of machine learning algorithms to be trained and fitted to a given dataset, as well as providing pre-processing techniques and methods for comparing and validating parameters to simplify the process of selecting the model
        that gives the best results.
      </p>
             
      <img src="./images/machine_learning_map.png" alt="catagories of machine learning" class="center">
      <p>As shown in the above diagram, machine learning algorithms can be divided into 4 distinct categories.</p>
      
      <b>Supervised learning</b> - Covers models in which a labelled datasets is used to train algorithms to either classify or predict output values of a given dataset. 
        As input data is fed into the model an error function serves to evaluate the quality of the model prediction and adjusts the weights accordingly to reduce 
          the discrepancy. The algorithm then repeats this evaluation and optimisation process, updating weights until an accuracy threshold  has been satisfied.  
          Once derived, these model weights can then be applied to a previously unseen dataset to allow output predictions to be made.
        <ul>
          <li><b>Classification</b> - These algorithms are used to identify which category an object belongs to. Commonly used techniques include Support vector machines, logistic regression, nearest neighbours and random forest.</li>
          <li><b>Regression</b>- In contrast regression algorithms predict a specific value based on the provided inputs.</li>
        </ul>
        
        <b>Unsupervised learning</b> - These algorithms discover hidden patterns or data groupings in an unlabelled  datasets.  Their ability to 
        discover similarities and differences in information make them an ideal solution for many exploratory data analysis problems.
        <ul>
          <li><b>Clustering</b> - Automatically sorting similar objects into sets for applications such as customer segmentation using algorithms such as K-Means and spectral clustering </li>
          <li><b>Dimension reduction</b> - Reducing the number of random variables enables complex multidimensional data to be more easily visualised and reduces the computational cost of processing. 
            This approach forms the basis of collaborative filtering algorithms, used extensively in recommendation engine.</li>          
        </ul>
    </div>


    <h3 class="accordion">Deep learning</h3>
    <div class="panel">
      <br/>
      <p style="padding:3px;clear:both;"> 
        An artificial neural network (ANN) uses multiple layers between the inputs and outputs of a model to enable more complex relationships to be inferred. 
        While ANN's can be applied to all types of dataset, they truly excel when modelling complex entities such as images, sound and language, 
        where the significance of a piece of data is a function of the datapoints around it. Popular libraries for implementing deep learning models include 
        <a href="https://www.tensorflow.org/"   target="_blank">Tensorflow</a>, developed by Google and <a href="https://pytorch.org/">Pytorch</a> from Facebook.
      </p>
      <img src="./images/neutral-network-diagram.png" alt="neural network" class="center">
      <p>The four main types of ANN we consider are:</p>
      <ul>
        <li><b>Convolutional Neural Networks</b> - Used extensively for image processing a CNN is able to reduce an image into a form suitable for processing, 
          without losing features which are critical for obtaining a good prediction. Passing the image through a range of filters and aggregating 
          the values assigned to cells enables low-level features such as edges, colour, gradient and orientation to be captured. These low-level features are then 
          combined in subsequent layers to obtain a high-level understanding of the image content. 
        </li>
        <li><b>Recurrent Neural Networks</b> - Analyse sequences of data and are used extensively for language processing and applications to interpret streamed IOT sensor data.  Pretrained libraries 
          such as <a href="https://spacy.io/">Spacy</a> provide powerful pretrained models that can be used to identify different parts of speech, sentiment and word similarity
          directly of a given piece of text.</p>
          <li><b>Reinforcement Learning</b> - Is a behavioural machine learning model that, instead of being trained using sample data, learns to maximise reward through experimentation. 
            As the algorithm progressively learns the sequence of behaviours that return the most successful outcomes it devises a policy to deliver the optimal response to a given situation.</li>  
        <li><b>Generative Adversarial Networks</b> - Discover and learn the regularities or patterns in input data in such a way that the model can be 
          used to generate new examples that plausibly could have been drawn from the original dataset.  This technique has been used to translate photographs across domains, 
          such as day to night or summer to winter, generate high-resolution versions of input images or even create new music, images and texts in the style of a particular artist.
        </li>     
      </ul>
    </div>

    <h3 class="accordion">Visualisation</h3>
    <div class="panel">
      <br/>      
      <p>
        The purpose of visualisation is to augment the human capabilities by representing a dataset in such a way that it helps people to carry out their tasks more effectively.  
        In general, these tasks can be split into 2 categories:
      </p>
      <ul>
        <li><b>Presentation </b> - Communicating known facts to a target audience.</li>
        <li><b>Discovery </b> - Finding new knowledge through either helping form or confirm a hypothesis.</li>
      </ul>
      <p>
        Data is conveyed through a mixture of marks and channels. A mark is a basic geometric element, point (1d), line (2d) and area (3d) used to depict an item or connection 
        while the channels control the appearance of the marks to express both ordinal and categorical attributes.  Examples of commonly used channels are shown in the diagram below.
      </p>

      <img src="./images/vis.png" alt="visulaisation channels" class="center">
      <p>
        The advantage of delivering visualisations over a web page is that it opens the option to make the images dynamic, using motion as an additional channel 
        and allowing the user to manipulate the image to overcome some of the limitations of a traditional static image.  Possible interactions include:
      </p>
      <ul>
        <li>Aggregating and filter information as required.</li>
        <li>Panning and rotating around a space to explore.</li>
        <li>Zooming and /or the use of a tooltip for closer inspection of specific data points.</li>
        <li>Linked charts to show correlation between attributes.</li>
      </ul>
      <p>
        Regardless of the nature of the data or the purpose of the visualisation it is worth ensuring that the charts you create adhere to the design principals defined by Edward Tufte. 

      </p>
      <ul>
        <li>Clear detailed and though labelling.</li>
        <li>Graphic effects should be proportional to the numerical quantities.</li>
        <li>Minimise the use of unnecessary ink distracting from the core data.</li>
        <li>Avoid cluttering charts with unnecessary.</li>
      </ul>
      <p>
        For static charts <a href="https://matplotlib.org/">matplotlib</a> and <a href="https://seaborn.pydata.org/">seaborn</a> are generally considered the standard 
        Python visualisation libraries.  As an alternative we also find <a href="https://plotnine.readthedocs.io/">plotnine</a>, 
        which is a Python implementation of a grammar of graphics, provides a powerful method of iteratively building complex and professional looking plots.  
        For interactive plots <a href="https://plotly.com/">plotly</a> is our library of choice offering tooltips, filters, panning and zoom functionality as standard and can be easily integrated 
        directly into a web application.
      </p>
      <p>For a more comprehensive discussion of the art of effective data visualisation  we recommend <a href="https://www.cs.ubc.ca/~tmm/vadbook/">Visualization Analysis and Design</a> By Tamara Munzner</p>


    </div>

    <h3 class="accordion">Machine learning in production</h3>
    <div class="panel">
      <br/>      
      <p>
        Training a machine learning model is only a small part of the process involved in creating a productionsied machine learning service.  MLOps is the discipline of managing
        the complete machine learning lifecycle from data ingestion and model development through to monitoring and maintaining the model in a production environment, ensuring it
        continues to operate as expected. The diagram below illustrates the 7 principle steps involved in a machine learning pipeline and includes details of the tools provided by
        the <a href="https://www.tensorflow.org/tfx/tutorials">TensorFlow Extended (TFX)</a> platform, that can used to deliver a robust and repeatable process as the model size and complexity increases.
      </p>

      <img src="./images/TFX.png" alt="TensorFlow Extended" class="center">

      <p>
        In a production environment machine learning models are constantly impacted by external factors which can result in degradation of performance.  The main changes are impacting a model performance include:
        <ul>
          <li><b>Data drift -</b> Changes in data over time.  This can be driven by seasonality, trends or potential a step change in how data is recorded. </li>
          <li><b>Concept drift – </b>Changes in the desired outcomes overtime, which can be driven by changes in policy.</li>
          <li><b>Model resilience –</b> Ensuring that the model can handle problems with data collection and system problems.</li>
        </ul>
      </p>

    </div>

    <h3 class="accordion">Data Validation</h3>
    <div class="panel">
      <br/>      
      <p>
        In order to validate data it is necessary to have a baseline against which the data can be compared.  A data schema is used to define the data fields, types and various 
        parameters such as a categorical vocabulary or continuous data limits.  <a href="https://www.tensorflow.org/tfx/data_validation/get_started">TensorFlow Data Validation (TFDV)</a> allows the automatic generation of a schema and the various 
        parameters including baseline statistics that can then be evaluated over time to observe any changes and trigger alerts or model retraining as required.      
      </p>

      <img src="./images/TFX_schema.png" alt="TensorFlow Schema" class="center">
      

    </div>


    <h3 class="accordion">Feature Engineering</h3>
    <div class="panel">
      <br/>      
      <p>
        Feature engineering is about manipulating the raw data into a format that provides the greatest possible predictive power.  The key feature engineering processes include:        
      </p>
      <img src="./images/Feature_eng.png" alt="Feature Engineering" class="center">
        <ul>
          <li><b>Data cleansing –</b> Managing errors, omissions and formatting inconstancies in the data.</li>
          <li><b>Feature tuning –</b> Scaling and normalising the data to improve predictive power by ensuring variables are compared on an equal footing.</li>
          <li><b>Representation transformation –</b> The process of changing the format, structure or values of data to provide greater meaning. Examples include binning and bucketing 
            values into discreet groups, using embedding’s to represent meaning within text.</li>
          <li><b>Feature construction –</b>Inferring new data from the existing.  An example would include converting a date field to create a variable indicating the day of the week 
            or using two geographical co-ordinates to infer a distance between locations.</li>
          <li><b>Feature Selection –</b> The performance of a machine learning model is a balance between reducing the number of input variables while ensuring the information required in 
            those variable is sufficient to infer the required output.  A number of approaches to reduce the complexity of the inputs can be used including.
            <ul>
              <li>Univariate feature selection selects the ‘n’ features with the strongest link to the label to be predicted.</li>
              <li>Wrapper methods look to progressive add or remove features from the model and observes the impact on performance to derive an optimum subset of features.</li>
              <li>Embedding techniques such as Principal component analysis look to derive new features that encapsulate all the information in a reduced number of dimensions.</li>
            </ul>
          </li>
        </ul>
        
      <p>
        Using Tensorflow transform library enables the above steps can be encapsulated into a pipeline that can be executed consistently on all data items, both the training and predicting data.
        MetaData can then also be produced to track the lineage of the data flowing between components in the pipeline as artefacts that are stored in a dedicated database 
      </p>
      

    </div>


    <h3 class="accordion">Model Training</h3>
    <div class="panel">
      <br/>      
      <p>
        Every type of machine learning model has a number of hyper parameters that need to be selected to optimise the model performance.  Parameters can be either:
      </p>
      <ul>
        <li><b>Model hyperparameters —</b> define the fundamental construct of a model itself, which can include neural network architecture attributes such as filter size, pooling, stride and padding.</li>
        <li><b>Optimizer hyperparameters —</b> are related to how the model learns the patterns based on data.</li>
      </ul>
      <p>
        When selecting optimiser hyperparameters for simple machine learning models a grid search is often used to fully train the model and evaluate the model using a range of parameters and the selecting 
        those that deliver the best performance.  However when evaluating deep learning models it is often impractical to perform an exhaustive search so it is necessary to use some other heuristics to shortlist options. 
      </p>
      <p>
        KerasTuner provides a number of search algorithms to explore a defined search space to find the best hyper-parameter values for your models. KerasTuner comes with the following algorithms:
      </p>
      <ul>
      <li><b>Bayesian Optimization -</b> Instead of searching every possible combination, the Bayesian Optimization tuner follows an iterative process, where it chooses the first few at random. 
        Then, based on the performance of those hyperparameters, the Bayesian tuner selects the next best possible.</li>
      <li><b>Hyperband -</b>early-stopping to speed up the hyperparameter tuning process. The main idea is to fit a large number of models for a small number of epochs and to only continue 
        training for the models achieving the highest accuracy on the validation set.</li>     
      </ul>

      <p>
        Given the complexity involved in defining an optimum neural network the best option may be to utilise automatic model architectures selection tools available of all the main 
        cloud platforms.  Click on the following links for a more detailed description of these services:
      </p>
      <ul>
        <li><a href="https://aws.amazon.com/sagemaker/autopilot"></a>Amazon SageMaker Autopilot</a></li>
        <li><a href="https://azure.microsoft.com/en-in/services/machine-learning/automatedml/"></a>Microsoft Azure Automated Machine Learning</a></li>
        <li><a href="https://cloud.google.com/automl"></a>Google Cloud AutoML</a></li>
      </ul>


    </div>


    <h3 class="accordion">Validating a model / Evaluation Metrics</h3>
    <div class="panel">
      <br/>      
      <p>
        As discussed earlier a model is typically used to either label a data point or to infer a output value based on the provided inputs. 
        For either of these types of model a common set of metrics are used to evaluate performance:
      </p>
      <p><b>Classification metrics</b></p>
      <ul>
        <li><b>Precision -</b> the ratio of true positives over the sum of false positives and true negatives.</li>
        <li><b>Recall -</b> the ratio of correctly predicted outcomes to all predictions. It is also known as sensitivity or specificity.</li>
        <li><b>Accuracy -</b> the ratio of correct predictions out of all predictions made by an algorithm. It can be calculated by dividing 
          precision by recall or as 1 minus false negative rate (FNR) divided by false positive rate (FPR).</li>
        <li><b>F1-score -</b> combines these three metrics into one single metric that ranges from 0 to 1 and it takes into account both Precision and Recall.</li>
      </ul>

      <p><b>Regression metrics</b></p>
      <ul>
        <li><b>Mean Absolute Error -</b> is the average distance between predicted and actual values however it doesn’t give any idea about the direction of the error 
          which is whether we are under or over predicting our data.</li>
        <li><b>Mean Squared Error -</b> uses the square of average difference between predicted and actual values. By taking the square of errors it penalises larger errors more heavily.</li>
      </ul>
      <p>Tensorflow provides a couple of tools that simplify the collection of metrics</p>
      <ul>
        <li><b>TensorBoard -</b> is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy,
           visualizing the model graph and other useful features such as projecting embedding’s to a lower dimensional space.</li>
        <li><b>Tensorflow Model analysis –</b> enables changes to be observed over time to reflect trends and seasonality.  An additional capability this tool provides is the ability to slice the data 
          to reveal where particular data segments are not well catered for (e.g. specific customer segments)</li>
      </ul>
    

    </div>

    <h3 class="accordion">Serving the model</h3>
    <div class="panel">
      <br/>      
      <p>
        When it comes to serving a model you need to be cognisant of the environment in which it is going to be operated.  Model serving is a constant balancing act between accuracy, latency and cost. 
        While complex models will usually provide more accurate predictions there size can be prohibitive, especially when running on relatively low powered devices such as mobile phones. 
      </p>
      <p>
        A number of techniques exist to simplify a model for operating on IOT and mobile devices.  The techniques include:
      </p>
      <ul>
        <li>Principal component analysis (PCA) - used to reduce the dimensionality of the inputs to a model and therefor simplify the model architecture required.</li>
        <li>Quantizing a model - Reduce the size and latency of the model by effectively simplifying the weights applied to each layer.  Quantization can be either performed 
          before or after initial training.  Post training quantisation involves simplify a model by using integer-only arithmetic, which can be implemented more efficiently than floating point inference.  Alternatively quantisation can be performed during training to constrain the parameters that can be applied.</li>
        <li>Pruning - reduces the size of a model by removing some of the connections between nodes and therefore reduces the number of parameters in a network.</li>
        <li>Knowledge distillation is a method of transferring the knowledge learnt using a complex “teacher” model into a more simple light weight “student” model.  
          The key here is that instead of learning the relationship between the inputs and the labels the ”student” model aims to learn the softer targets of a “teacher” 
          probability distribution.</li>

      </ul>
      <p>Where high performance modelling is required distribution strategies may need to be considered to allow the model to be processed over numerous machines.  Here techniques include:</p>
      <ul>
        <li>Data parallelism - Data is split into a number of subsets which enables each machine to work on a subset of total data set so that it can be loaded into memory.  
          Each worker than synchronises the parameter updates to set the model parameters.</li>
        <li>Model Parallelism- Where the models are extremely large it is possible to partition the model into sections and assign them to different machines.</li>
        <li>Pre-processing pipeline parallelism –  By paralyzing the activities to fetch read, transform and train a model the idle time of expensive compute resources can be minimised.  
          Typically cloud implementations of Giant Neural Networks are performed on cloud computers such as Google GPipe or Microsoft PipeDream </li>
      </ul>     

    </div>


    <h3 class="accordion">The <span id="brand">EMPEDATA</span> difference</h3>
    <div class="panel">
      <br/>
      <p>
        We know, as an SME, you need to see return on investment fast and it is therefore essential to quickly demonstrate the value your digital service transformation will deliver!
        The <span id="brand">EMPEDATA</span> 4 week analytics demonstrator package is the perfect way to get started.
        This affordable package identifies and delivers a key capability to your business, which can then be used        
        as a catalyst to launch your wider digital service transformation aspirations.
        <ul>
          <li><b>Week 1</b> - Working closely with you to scope a business opportunity, identify potential data sources and document an agreed set of success criteria.</li>
          <li><b>Week 2</b> - Collating, cleaning and processing the available data into a format suitable for analysis</li>
          <li><b>Week 3</b> - Develop the analytical models that provide actionable insight.</li>
          <li><b>Week 4</b> - Finalise models, enhance visualisations, document and present the work performed.</li>
        </ul>
  
      </p>
      <p>To launch your <span id="brand">EMPEDATA</span> demonstrator package today please <a href="./contact.html">get in touch</a>.</p>
    </div>


    


    <h3 class="accordion">Learning resources</h3>
    <div class="panel">
      <br/>
      
      </li>
      <h4>Free resouces</h4>
      <ul>
        <li><a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb"><span>Python DataScience Handbook</span></a> - This free book provides a fantastic introduction to the main Python analytical libraries.</li>
        <li><a href="https://realpython.com/"><span>Real Python</span></a> - A heap of podcasts and tutorials that can be particularly useful for preparing data</li>
        <li><a href="https://machinelearningmastery.com/start-here/"><span>Machine Learning Mastery</span></a> - A great source of information when developing your own machine learning applications.</li>       
        <li><a href="https://www.khanacademy.org/"><span>Khan Academy</span></a> - Linear algebra, statistics and calculus are key to developing machine learning capabilities.  
        If you need to brush up these skills Khan Academy is a great resource.</ul>
      <h4>Subscription sites</h4>
      <ul>
        <li><a href="https://www.coursera.org/specializations/mathematics-machine-learning">Maths for Machine Learning</a> - Covers all the maths you will need to develop your understanding of machine learning</li>
        <li><a href="https://www.coursera.org/specializations/data-science-python">Data Science</a> - Acquire data science methods, techniques skills.</li> 
        <li><a href="https://www.coursera.org/specializations/tensorflow2-deeplearning"><span>Deep Learning</span></a> -A comprehensive guide to using TensorFlow to develop deep learning models.</li>
        <li><a href="https://www.coursera.org/specializations/information-visualization">Information Visualisation</a> - Design, evaluate and develop data visualisations</li>
        <li><a href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops">MLOPS</a> - Productionise your machine learning models</li>
        <li><a href="https://www.datacamp.com/"><span>Datacamp</span></a> - Covers all the basics of Python data analysis techniques and libraries with hands on tutorials </li>
      </ul>

      <h4>Recommended books</h4>
      <ul> 
        <li><a href="https://www.taylorfrancis.com/books/mono/10.1201/9780429428357/introduction-probability-joseph-blitzstein-jessica-hwang">Introduction to Probability</a> By Joseph K. Blitzstein, Jessica Hwang</li> 
        <li><a href="https://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a> By Gilbert Strang</li> 
        <li><a href="https://www.cambridge.org/us/academic/subjects/computer-science/algorithmics-complexity-computer-algebra-and-computational-g/networks-crowds-and-markets-reasoning-about-highly-connected-world">Networks, Crowds, and Markets</a> By Jon Kleinberg</li>
        <li><a href="https://www.cengage.co.uk/books/9781305270107/">Introductory Econometrics</a> By Jeffrey M. Wooldridge</li>  
        <li><a href="https://www.wiley.com/en-au/Modeling+and+Simulation+of+Discrete+Event+Systems-p-9781118386996">Modeling and Simulation of Discrete Event Systems</a> By Byoung Kyu Choi, DongHun Kang</li> 
        <li><a href="https://mitpress.mit.edu/books/probabilistic-graphical-models">Probabilistic Graphical Models</a> By Daphne Koller and Nir Friedman</li> 
        <li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a> By Jake VanderPlas</li> 
        <li><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning</a> By Aurélien Géron</li> 
        <li><a href="https://www.manning.com/books/deep-learning-with-python">Deep Learning with Python</a> By François Chollet</li> 
        <li><a href="https://www.cs.ubc.ca/~tmm/vadbook/">Visualization Analysis and Design</a> By Tamara Munzner</li> 

 

      </ul>



    </div>

    <br/>

 

 
    <br/>
    <h2>Project Portfolio</h2>

    <div id="home-tiles" class="row">

      <div class="col-lg-4 col-md-4 col-sm-6 col-xs-12">
        <div class="tile" id="ac_health-tile" onclick="document.getElementById('id01').style.display='block'"><span>Aircraft prognostics</span></div>
      </div>

      <div class="col-lg-4 col-md-4 col-sm-6 col-xs-12">
        <div class="tile"  id="music-tile" onclick="document.getElementById('id02').style.display='block'"><span>Royalty forecasting</span></div>
      </div>

      <div class="col-lg-4 col-md-4 col-sm-6 col-xs-12">
        <div class="tile" id="NLP-tile" onclick="document.getElementById('coming_soon').style.display='block'"><span>Language Processing</span></div>
      </div>

      <div class="col-lg-4 col-md-4 col-sm-6 col-xs-12">
        <div class="tile" id="email-tile" onclick="document.getElementById('coming_soon').style.display='block'"><span>network analysis</span></div>
      </div>

      <div class="col-lg-4 col-md-4 col-sm-6 col-xs-12">
        <div class="tile" id="twitter-tile" onclick="document.getElementById('coming_soon').style.display='block'"><span>Sentiment Analysis</span></div>
      </div>

    </div><!-- End of #home-tiles -->
  </div><!-- End of main content -->
  



  <div id="id01" class="modal">
    <div class="modal-content card-4 animate-zoom">
      <header class="modal_container blue"> 
        <span onclick="document.getElementById('id01').style.display='none'" class="button blue xlarge display-topright">&times;</span>
        <h2>Aircraft Prognostics</h2>
      </header>

      <div class="bar border-bottom">
        <button class="tablink bar-item button" onclick="openProject(event, 'Objective','project1')">Objective</button>
        <button class="tablink bar-item button" onclick="openProject(event, 'Hypothesis','project1')">Approach</button>
        <button class="tablink bar-item button" onclick="openProject(event, 'Outcome','project1')">Outcome</button>
      </div>

      <div id="Objective" class="modal_container project1">
        <br>
        <p>Autonomous aircraft, requiring no human interventions during operation, is a rapidly evolving sector.
          The global autonomous aircraft market was estimated to be USD 4.56 billion in 2019 and is projected to reach USD 16.23 billion by 2027.</p>
          
        <p>With such competition and growth potential manufacturers are looking towards enhanced service strategies as a means of delivering a competative advantage</p>
        <p>In responce to this opportunity we were commissioned to perform a comprehensive review intelligent health management solutions
          and develop a prototype solution utilising advanced analytics to demonstrate an approach to deliver adaptive vehicle health management, 
          providing greater process control, reduced operating costs and enhanced availability.
        </p>
        <br>
      </div>

      <div id="Hypothesis" class="modal_container project1">
        <br>
        <p>The approach taken involved decomposing this top-level objective into three targeted
          value propositions. 
          <ul>
            <li>Accurately predicting the remaining useful life of aircraft components based on the provided sensor data</li>
            <li>Providing dynamic fault diagnostics advice to the maintainer based on the observations</li>
            <li>Simulating the degradation of the aircraft and the potential maintenance decisions to determine the optimum responce 
              based on defined objective funcitons and within defined operational constraints.</li>
          </ul>

        <br>
      </div>

      <div id="Outcome" class="modal_container project1">
        <br>
        <p>Aviation will always mandate stringent safety requirements, however the ability to
          reduce uncertainty regarding the health of components presents an enormous
          opportunity to reduce cost and drive operational efficiencies.
        </p>
          The novel approach developd here, normalising the aircraft sensors data based on flight condition, to train a Long-Term-ShortTerm-Memory (LSTM) model  
          demonstrated the ability to predicting the degradation state of these complex systems, with supporting confidence intervals, and
          demonstrate how a move to a condition-based maintenance strategy could be realised. 
        </p>
        <p>The use of Bayesian Belief Networks (BBNs) provided the requried adaptive diagnostic advice to the
          maintainer in an intuitive and visual way.  This approach had the additional benefit of enabling any divergence from the designed system reliability</p>
        <p>
          Performing a monte-carlo analysis on the simulation combined with a dual annealing optimisation function enabled:
          <ul>
            <li>An optimised stocking policy to be proposed, based on both financial and aircraft availability constraints.</li>
            <li>Opportunity maintenance to be identified (proactively replacing an item early) to reduce cost and better utilise limited manpower and hangar capacity</li>
          </ul>
        </p>
      </div>

      <div class="modal_container light-grey padding">
        <button class="button right white border" onclick="document.getElementById('id01').style.display='none'">Close</button>
      </div>
    </div>
  </div>


  <div id="id02" class="modal">

    <div class="modal-content card-4 animate-zoom">
      <header class="modal_container blue"> 
        <span onclick="document.getElementById('id02').style.display='none'" class="button blue xlarge display-topright">&times;</span>
        <h2>Royalty Forecasting</h2>
      </header>

      <div class="bar border-bottom">
        <button class="tablink bar-item button" onclick="openProject(event, 'Objective2', 'project2')">Objective</button>
        <button class="tablink bar-item button" onclick="openProject(event, 'Hypothesis2','project2')">Approach</button>
        <button class="tablink bar-item button" onclick="openProject(event, 'Outcome2','project2')">Outcome</button>
      </div>

      <div id="Objective2" class="modal_container project2">
        <br>
        <p>An international accounting firm whose clients represent some of the worlds leading peforming artists had aspirations to provide increased clarity to their clients when managing their future revenue potential.</p>
        <p>
          The firm provided over 10 years of revenue information for a number of artists, which incorported revenues derived from streaming, perfoming, merchandise sales and syncronsiation rights (TV, movie, video games or advertising).
          The challenge set was to apply a varierty of analytical techniques to this data to enable more accurate and efficent revenue 
          forecasts to be generated when compared to the traditional approach being used.
        </p>
      </div>

      <div id="Hypothesis2" class="modal_container project2">
        <br>
        <p>The approach taken involved:</p>
          <ul>
            <li>Developing a method to consolidate disparte records and identify key attributes into defined data structure suitable for analysis.</li> 
            <li>Assessing a varierty of machine learning, curve fitting and time series methodologies to predict future royalties</li>
            <li>Augment the existing data with additional publically available information to improve the predictive capability of the proposed solution</li>
          </ul>
      </div>

      <div id="Outcome2" class="modal_container project2">
       <br>
        <p>From analysis at an individual song level the revenues generated were found to follow a decay curve, initially growing as the songs populatirty increased before begining to decline</p><br>
        <p>Using a modified version of the <a href=https://en.wikipedia.org/wiki/Bass_diffusion_model#:~:text">Bass Diffusion Model</a>, used extensively for modelling future sales(shown below) we were able to accuratly fit the parameters in the equation for all the established songs in an artists catalogue</p>
        <img src="images/bass_model1.png" alt="bass model" width=175px>
        
        <p>The real challenge came in trying to predict future revenue for songs released in the last 6 months and therefore lacked the required historic information.  To overcome this problem we used the <a href="https://developer.spotify.com/documentation/web-api/">Spotify API</a> to obtain charecterisics of the song and artist and 
          use them to train a model to predict the co-efficents of innovation and immitation.</p> 
      </div>

      <div class="modal_container light-grey padding">
        <button class="button right white border" onclick="document.getElementById('id02').style.display='none'">Close</button>
      </div>
    </div>

  </div>

  
  <div id="coming_soon" class="modal">
    <div class="modal-content animate-zoom">
      <div class="modal_container modal_background">
        <span onclick="document.getElementById('coming_soon').style.display='none'" class="button blue display-topright">&times;</span>
        <img class="modal_img" src="./images/EMPEDATA.png" alt="logo">
        <div class="typing">
            <div class="typing-effect">
                COMING SOON
            </div>
        </div>
      </div>
    </div>
  </div>


  <script>
    document.getElementsByClassName("tablink")[0].click();
    document.getElementsByClassName("tablink")[3].click();
    function openProject(evt, projectName,proj) {
      var i, x, tablinks;

      x = document.getElementsByClassName(proj);
      for (i = 0; i < x.length; i++) {
        x[i].style.display = "none";
      }
      tablinks = document.getElementsByClassName("tablink");
      for (i = 0; i < x.length; i++) {
        tablinks[i].classList.remove("light-grey");
      }

      document.getElementById(projectName).style.display = "block";
      evt.currentTarget.classList.add("light-grey");
    };

  </script>






<footer>
  <div class="container" > 
    <a href="index.html"><img style="float:left" src="./images/EMPEDATA_s.png" alt="logo"></a>
    <a href="index.html"><div style="float:left">
      <span id="footer1">EMPEDATA.com</span>
      <p id="footer1_sub">South Petherton, Somerset. UK</p>
    </div></a>
    <a href='#top' style="float:right">
      <img src="images/back-to-top.png" alt="Back to top" class="center" style="width: 50px;"/>
    </a>
  </div>
</footer>
  
<script>
  var acc = document.getElementsByClassName("accordion");
  var i;
  
  for (i = 0; i < acc.length; i++) {
    acc[i].addEventListener("click", function() {
      this.classList.toggle("active");
      var panel = this.nextElementSibling;
      if (panel.style.maxHeight) {
        panel.style.maxHeight = null;
      } else {
        panel.style.maxHeight = panel.scrollHeight + "px";
      }
    });
  }
  </script>
  
  
  
  </body>
  </html>


